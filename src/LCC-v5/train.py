import torch
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import time 
import numpy as np

from load_dataset import load_dataset
from HistogramDataset import HistogramDataset
from ResNetModel import ResNetModel, angular_loss, train_one_epoch, evaluate
from config import get_base_dir, TRAIN_DIR, VAL_DIR, REAL_RGB_JSON_PATH, EPOCHS, OUTPUT_DIR, BATCH_SIZE, LEARNING_RATE, WEIGHT, SEED, ERASE_PROB, ERASE_SIZE, DEVICE, set_seed, ACCUMULATION_STEPS


def main():
    set_seed(SEED) 
    rng = np.random.default_rng(SEED)
    base_dir = get_base_dir()
    print("Base dir:", base_dir)
    print(torch.cuda.is_available())  # Trueãªã‚‰OK
    print(torch.cuda.get_device_name())  # GPUåãŒå‡ºã‚‹
    
    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    X_train, y_train_df = load_dataset(TRAIN_DIR, REAL_RGB_JSON_PATH)
    X_val, y_val_df = load_dataset(VAL_DIR, REAL_RGB_JSON_PATH)
    # å‡ºåŠ›ãŒX= numpy Y=df
    
    # 2. Tensorã«å¤‰æ›
    y_train = y_train_df[["R", "G", "B"]].values
    y_val = y_val_df[["R", "G", "B"]].values
    
    print(f"X_train.shape = {X_train.shape}, y_train.shape = {y_train.shape}")
    print(f"X_val.shape = {X_val.shape}, y_val.shape = {y_val.shape}")

    # 3. TensorDatasetä½œæˆï¼ˆã“ã“ã§ erase æ©Ÿèƒ½ã‚’çµ„ã¿è¾¼ã‚€ï¼‰
    train_dataset = HistogramDataset(X_train, y_train, erase_prob=ERASE_PROB, erase_size = ERASE_SIZE,rng=rng)
    val_dataset = HistogramDataset(X_val, y_val,rng=rng)

    # 4. DataLoaderä½œæˆ pin_memory=Trueã“ã‚Œã‚’ä½¿ã†ã¨GPUã¸ã®è»¢é€ãŒé€Ÿããªã‚‹
    train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True, persistent_workers=False)
    val_loader = DataLoader(val_dataset, BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True, persistent_workers=False)


    # 5. ãƒ¢ãƒ‡ãƒ«å®šç¾©
    model = ResNetModel().to(DEVICE)
    try:
        model = torch.compile(model, backend="eager")
    except Exception as e:
        print(f"torch.compile failed: {e}")
    # Adamã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã§å­¦ç¿’
    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT)


    # æå¤±é–¢æ•°ã¯RGBãƒ™ã‚¯ãƒˆãƒ«é–“ã®è§’åº¦èª¤å·®
    loss_fn = angular_loss


    # å­¦ç¿’è¨˜éŒ²ç”¨ãƒªã‚¹ãƒˆ
    train_losses = []
    val_losses = []

    all_start_time =time.time()

    for epoch in range(EPOCHS):
        print(f"\n==== Epoch {epoch+1}/{EPOCHS} ====")

        # ğŸ”¸ Epochã®ç·æ™‚é–“è¨ˆæ¸¬é–‹å§‹
        epoch_start_time = time.time()

        train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, accumulation_steps=ACCUMULATION_STEPS)
        val_loss = evaluate(model, val_loader, loss_fn)

        # ğŸ”¹ Epochç·æ™‚é–“
        epoch_end_time = time.time()
        print(f"Total epoch time: {epoch_end_time - epoch_start_time:.2f} sec")

        # ğŸ”¸ ãƒ­ã‚°ä¿å­˜
        print(f"Loss: Train = {train_loss:.4f}, Val = {val_loss:.4f}")
        train_losses.append(train_loss)
        val_losses.append(val_loss)


    # 7. ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    torch.save(model.state_dict(), OUTPUT_DIR / 'resnet_model.pth')
    plt.savefig(OUTPUT_DIR / 'loss_curve.png')

    all_end_time = time.time()

    print(f"â˜†Total all time: {all_end_time - all_start_time:.2f} sec")
    
    # 8. å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid(True)
    plt.show()



if __name__ == "__main__":
    main()