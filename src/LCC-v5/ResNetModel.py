import torch
import torch.nn as nn
import torchvision.models as models
import torch.nn.functional as F
from torchvision.models import ResNet18_Weights

from config import DROPOUT, OUTPUT_DIM, DEVICE

# ResNet18ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸã‚«ãƒ©ãƒ¼æ¨å®šãƒ¢ãƒ‡ãƒ«ï¼ˆå…¥åŠ›: 1ch, å‡ºåŠ›: RGBãƒ™ã‚¯ãƒˆãƒ«ï¼‰
class ResNetModel(nn.Module):
    def __init__(self, output_dim = OUTPUT_DIM, dropout_rate = DROPOUT):
        super().__init__()
        weights = ResNet18_Weights.DEFAULT
        model = models.resnet18(weights=weights)

         # conv1 ã®é‡ã¿ã‚’1chç”¨ã«å¤‰æ›ï¼ˆ3ch â†’ å¹³å‡ã§1chã¸ï¼‰
        pretrained_weight = model.conv1.weight
        new_weight = pretrained_weight.mean(dim=1, keepdim=True)

        # å…¥åŠ›ãƒãƒ£ãƒ³ãƒãƒ«ã‚’1chï¼ˆã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã‚„ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ç”»åƒï¼‰ã«å¤‰æ›´
        model.conv1 = nn.Conv2d(
            in_channels=1,       # å…¥åŠ›ã¯1ãƒãƒ£ãƒãƒ«
            out_channels=64,     # å‡ºåŠ›ã¯64ãƒãƒ£ãƒãƒ«ï¼ˆResNetæ¨™æº–ï¼‰
            kernel_size=7,
            stride=2,
            padding=3,
            bias=False
        )
        model.conv1.weight.data = new_weight
        
        self.model = model


        # æ—¢å­˜ã®fcå±¤ã®å‰ã«Dropoutã‚’æŒŸã‚€æ§‹é€ ã«å¤‰æ›´
        in_features = self.model.fc.in_features
        self.model.fc = nn.Sequential(
            nn.Dropout(p=dropout_rate),          # Dropoutã‚’è¿½åŠ 
            nn.Linear(in_features, output_dim)   # æœ€çµ‚å‡ºåŠ›
        )

        
    def forward(self, x):
        return self.model(x)  # é †ä¼æ’­ï¼ˆå‡ºåŠ›ã¯ shape: [batch_size, 3]ï¼‰


# ğŸ”ºè§’åº¦ãƒ™ãƒ¼ã‚¹ã®æå¤±é–¢æ•°ï¼ˆè‰²ãƒ™ã‚¯ãƒˆãƒ«ã®æ–¹å‘ã‚’æ¯”è¼ƒï¼‰
def angular_loss(pred, target):
    """
    pred: ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ› (N, 3)
    target: æ­£è§£ã®RGBæ¯”ç‡ãƒ™ã‚¯ãƒˆãƒ« (N, 3)
    â†’ å‡ºåŠ›ãƒ™ã‚¯ãƒˆãƒ«ã¨æ­£è§£ãƒ™ã‚¯ãƒˆãƒ«ã®è§’åº¦ï¼ˆcosé¡ä¼¼åº¦ï¼‰ã§èª¤å·®ã‚’è¨ˆç®—
    """
    pred_norm = F.normalize(pred, dim=1)     # å‡ºåŠ›ã‚’L2æ­£è¦åŒ–ï¼ˆé•·ã•ã‚’1ã«ï¼‰
    target_norm = F.normalize(target, dim=1) # æ­£è§£ã‚‚L2æ­£è¦åŒ–

    cos_sim = (pred_norm * target_norm).sum(dim=1)  # å„ãƒ™ã‚¯ãƒˆãƒ«é–“ã®cosé¡ä¼¼åº¦
    cos_sim = torch.clamp(cos_sim, -1.0, 1.0)
    
    loss = 1 - cos_sim  # cosÎ¸ãŒé«˜ã„ï¼ˆæ–¹å‘ãŒä¸€è‡´ï¼‰ã»ã©æå¤±ãŒå°ã•ã„
    return loss.mean()  # ãƒãƒƒãƒå¹³å‡ã®æå¤±ã‚’è¿”ã™


# ğŸ” 1ã‚¨ãƒãƒƒã‚¯åˆ†ã®è¨“ç·´å‡¦ç†
def train_one_epoch(model, loader, optimizer, loss_fn):
    model.train()  # è¨“ç·´ãƒ¢ãƒ¼ãƒ‰ï¼ˆDropoutã‚„BatchNormã‚’æœ‰åŠ¹åŒ–ï¼‰
    total_loss = 0.0

    for X_batch, y_batch in loader:
        X_batch = X_batch.to(DEVICE)
        y_batch = y_batch.to(DEVICE)

        optimizer.zero_grad()               # å‹¾é…ã®åˆæœŸåŒ–
        pred = model(X_batch)               # ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ï¼ˆé †ä¼æ’­ï¼‰
        loss = loss_fn(pred, y_batch)       # æå¤±ã‚’è¨ˆç®—
        loss.backward()                     # å‹¾é…è¨ˆç®—ï¼ˆé€†ä¼æ’­ï¼‰
        optimizer.step()                    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°

        total_loss += loss.item()           # ãƒãƒƒãƒã”ã¨ã®æå¤±ã‚’è“„ç©

    average_loss = total_loss / len(loader)  # ãƒãƒƒãƒæ•°ã§å‰²ã£ã¦å¹³å‡æå¤±ã‚’ç®—å‡º
    return average_loss


# ğŸ” è©•ä¾¡é–¢æ•°ï¼ˆæ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆç”¨ï¼‰
def evaluate(model, loader, loss_fn):
    model.eval()  # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ï¼ˆDropoutã‚„BatchNormã‚’ç„¡åŠ¹åŒ–ï¼‰
    total_loss = 0.0

    with torch.no_grad():  # å‹¾é…ã‚’è¨ˆç®—ã—ãªã„ï¼ˆæ¨è«–ã®ã¿ã§é«˜é€Ÿãƒ»çœãƒ¡ãƒ¢ãƒªï¼‰

        for X_batch, y_batch in loader:
            X_batch = X_batch.to(DEVICE)
            y_batch = y_batch.to(DEVICE)

            pred = model(X_batch)               # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›
            loss = loss_fn(pred, y_batch)       # æå¤±ã‚’è¨ˆç®—
            total_loss += loss.item()

    average_loss = total_loss / len(loader)     # å…¨ä½“ã®å¹³å‡æå¤±
    return average_loss
