{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e4d2002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "65421fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(csv_dir, json_path):\n",
    "    # 1. JSON読み込みと辞書化\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    rgb_dict = {item[\"filename\"]: item[\"real_rgb\"] for item in json_data}\n",
    "\n",
    "    # 2. 特徴量とラベルの蓄積\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for filename in os.listdir(csv_dir):\n",
    "        if not filename.endswith(\"_masked.csv\"):\n",
    "            continue\n",
    "\n",
    "        base_id = filename.replace(\"_masked.csv\", \"\")  # 例: 8D5U5524\n",
    "\n",
    "        if base_id not in rgb_dict:\n",
    "            print(f\"Warning: {base_id} not in JSON, skipping\")\n",
    "            continue\n",
    "\n",
    "        csv_path = os.path.join(csv_dir, filename)\n",
    "        df = pd.read_csv(csv_path, header=None)\n",
    "\n",
    "        # 特徴量は1行と仮定してflatten\n",
    "        features = df.values.flatten()\n",
    "\n",
    "        X_list.append(features)\n",
    "        y_list.append(rgb_dict[base_id])\n",
    "\n",
    "    # DataFrame or numpy配列に変換\n",
    "    X = pd.DataFrame(X_list)\n",
    "    y = pd.DataFrame(y_list, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2f832dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1324)\n",
      "        R       G       B\n",
      "0   769.0  1043.0   653.0\n",
      "1  1664.0  2315.0  1464.0\n",
      "2   470.0   572.0   239.0\n",
      "3  1413.0  1735.0   836.0\n",
      "4   711.0   871.0   401.0\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "1319    0\n",
      "1320    0\n",
      "1321    0\n",
      "1322    0\n",
      "1323    0\n",
      "Name: 0, Length: 1324, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#load_datasetのテスト\n",
    "X, y = load_dataset(csv_dir=\"../histpre/\", json_path=\"../real_rgb.json\")\n",
    "\n",
    "print(X.shape)  # 特徴量の数 x サンプル数\n",
    "print(y.head()) # RGBのターゲット値\n",
    "\n",
    "print(X.iloc[0])  # 1番目のサンプルの特徴量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c09d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a31a3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def euclidean_loss(pred, target):\n",
    "    return torch.sqrt(((pred - target) ** 2).sum(dim=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74caf9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_chromaticity_loss(pred, target, eps=1e-8):\n",
    "    # クロマティシティ座標に変換：r = R/(R+G+B), g = G/(R+G+B)\n",
    "    pred_sum = pred.sum(dim=1, keepdim=True) + eps\n",
    "    target_sum = target.sum(dim=1, keepdim=True) + eps\n",
    "\n",
    "    pred_chroma = pred[:, :2] / pred_sum  # (r, g)\n",
    "    target_chroma = target[:, :2] / target_sum\n",
    "\n",
    "    loss = ((pred_chroma - target_chroma) ** 2).mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "576a86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, loss_fn):\n",
    "    model.train()  # モデルを訓練モードに設定\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()               # 勾配をリセット\n",
    "        pred = model(X_batch)               # 順伝播\n",
    "        loss = loss_fn(pred, y_batch)       # 損失計算\n",
    "        loss.backward()                     # 逆伝播\n",
    "        optimizer.step()                    # パラメータ更新\n",
    "\n",
    "        total_loss += loss.item()           # 損失を蓄積\n",
    "\n",
    "    average_loss = total_loss / len(loader)  # バッチ数で割る\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "94de0686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, loss_fn):\n",
    "    model.eval()  # 評価モードに切り替え\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # 勾配を計算しない（メモリ節約＆高速化）\n",
    "        for X_batch, y_batch in loader:\n",
    "            pred = model(X_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(loader)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7165637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # 1. データ読み込み\n",
    "    X_train_df, y_train_df = load_dataset('../histpre/', '../real_rgb.json')\n",
    "    X_val_df, y_val_df = load_dataset('../histpre', '../real_rgb.json')\n",
    "\n",
    "    # 2. Tensorに変換\n",
    "    X_train = torch.tensor(X_train_df.values, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train_df[[\"R\", \"G\", \"B\"]].values, dtype=torch.float32)\n",
    "    X_val = torch.tensor(X_val_df.values, dtype=torch.float32)\n",
    "    y_val = torch.tensor(y_val_df[[\"R\", \"G\", \"B\"]].values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    # 3. TensorDataset作成\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "    # 4. DataLoader作成\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # 5. モデル定義\n",
    "    model = MLPModel(input_dim=X_train.shape[1], hidden_dim=256, output_dim=2)\n",
    "    # SGDオプティマイザで学習\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    #　損失関数はクロマティシティ座標のMSE\n",
    "    loss_fn = mse_chromaticity_loss\n",
    "\n",
    "    # 6. 学習ループ\n",
    "    num_epochs = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # 学習記録用リスト\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn)\n",
    "        val_loss = evaluate(model, val_loader, loss_fn)\n",
    "        print(f\"Epoch {epoch+1:02d}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "        # ログ保存\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    # 7. モデル保存\n",
    "    torch.save(model.state_dict(), 'mlp_model.pth')\n",
    "   \n",
    "\n",
    "    # 8. 学習曲線の可視化\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c79233df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss = 42.0209, Val Loss = 0.0177\n",
      "Epoch 02: Train Loss = 0.0177, Val Loss = 0.0177\n",
      "Epoch 03: Train Loss = 0.0177, Val Loss = 0.0177\n",
      "Epoch 04: Train Loss = 0.0177, Val Loss = 0.0177\n",
      "Epoch 05: Train Loss = 0.0177, Val Loss = 0.0177\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1, 1, 2) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# 7. モデル保存\u001b[39;00m\n\u001b[32m     45\u001b[39m torch.save(model.state_dict(), \u001b[33m'\u001b[39m\u001b[33mmlp_model.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43mvisualize_rgb_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# 8. 学習曲線の可視化\u001b[39;00m\n\u001b[32m     49\u001b[39m plt.plot(train_losses, label=\u001b[33m'\u001b[39m\u001b[33mTrain Loss\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mvisualize_rgb_predictions\u001b[39m\u001b[34m(model, loader, num_samples)\u001b[39m\n\u001b[32m     24\u001b[39m axes[\u001b[32m0\u001b[39m].set_title(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrue\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrue_rgb.astype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m axes[\u001b[32m0\u001b[39m].axis(\u001b[33m'\u001b[39m\u001b[33moff\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpred_color\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (1, 1, 3) の形\u001b[39;00m\n\u001b[32m     28\u001b[39m axes[\u001b[32m1\u001b[39m].set_title(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPred\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpred_rgb.astype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m axes[\u001b[32m1\u001b[39m].axis(\u001b[33m'\u001b[39m\u001b[33moff\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T122115\\Desktop\\ColorConstancy\\ColorConstancy_env\\Lib\\site-packages\\matplotlib\\__init__.py:1521\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1518\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1526\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1527\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1528\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T122115\\Desktop\\ColorConstancy\\ColorConstancy_env\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:5979\u001b[39m, in \u001b[36mAxes.imshow\u001b[39m\u001b[34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[39m\n\u001b[32m   5976\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5977\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_aspect(aspect)\n\u001b[32m-> \u001b[39m\u001b[32m5979\u001b[39m \u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5980\u001b[39m im.set_alpha(alpha)\n\u001b[32m   5981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m im.get_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5982\u001b[39m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T122115\\Desktop\\ColorConstancy\\ColorConstancy_env\\Lib\\site-packages\\matplotlib\\image.py:685\u001b[39m, in \u001b[36m_ImageBase.set_data\u001b[39m\u001b[34m(self, A)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL.Image.Image):\n\u001b[32m    684\u001b[39m     A = pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28mself\u001b[39m._A = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[38;5;28mself\u001b[39m._imcache = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T122115\\Desktop\\ColorConstancy\\ColorConstancy_env\\Lib\\site-packages\\matplotlib\\image.py:653\u001b[39m, in \u001b[36m_ImageBase._normalize_image_array\u001b[39m\u001b[34m(A)\u001b[39m\n\u001b[32m    651\u001b[39m     A = A.squeeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A.ndim == \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A.shape[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m]):\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for image data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m A.ndim == \u001b[32m3\u001b[39m:\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[32m    657\u001b[39m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[32m    658\u001b[39m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[32m    659\u001b[39m     high = \u001b[32m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.issubdtype(A.dtype, np.integer) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: Invalid shape (1, 1, 2) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ColorConstancy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
